{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"Hack_task.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZY7ujkP_7WT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "from sklearn import preprocessing\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import datetime\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOdVHLI4A_zb",
        "outputId": "814f6d2c-2785-44d9-e1b7-b64e2e2cf8b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/hacks/train.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/hacks/test.csv\")"
      ],
      "metadata": {
        "id": "wD8_AVdsBCQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "ZkSXyLroohJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(path, has_target):\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "\n",
        "    df_weeks = [df[df['Week'] == w].drop(columns=['Week']).set_index(['Id']) for w in range(4)]\n",
        "\n",
        "\n",
        "    \n",
        "    if has_target:\n",
        "        df_target = df_weeks[0]['target']\n",
        "        df_weeks = [df.drop(columns=['target']) for df in df_weeks]\n",
        "    \n",
        "    for w in range(4):\n",
        "        df_weeks[w].columns = [f'{col}_w{w}' for col in df_weeks[w].columns]\n",
        "    df_res = df_weeks[0].join(df_weeks[1:])\n",
        "    \n",
        "    if has_target:\n",
        "        return df_res, df_target\n",
        "    return df_res"
      ],
      "metadata": {
        "id": "bxOSr7zUopQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = read_data('/content/drive/MyDrive/hacks/train.csv', has_target=True)\n",
        "X_test           = read_data('/content/drive/MyDrive/hacks/test.csv',  has_target=False)"
      ],
      "metadata": {
        "id": "OPDaUO9ooph0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')  # just to silence the warnings\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_LnhVHqopt0",
        "outputId": "185314f4-af7a-4972-d067-14c82c89fcf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(eval_metric='logloss', use_label_encoder=False)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = clf.predict_proba(X_test)[:, 1]\n",
        "res = pd.DataFrame(y_test, columns=['Predicted'])\n",
        "res.index = X_test.index\n",
        "res.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "029yNcL_op9U",
        "outputId": "2f28d2ff-9a77-4867-8a05-b6e143efb5bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d72fa560-0d4e-4a70-b8c7-2fafa0ab5555\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6107424960806386948</th>\n",
              "      <td>0.007021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-1808613790090531322</th>\n",
              "      <td>0.014067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-2649749947427248381</th>\n",
              "      <td>0.951422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4684257435812939224</th>\n",
              "      <td>0.249799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-7030158396775705152</th>\n",
              "      <td>0.030545</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d72fa560-0d4e-4a70-b8c7-2fafa0ab5555')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d72fa560-0d4e-4a70-b8c7-2fafa0ab5555 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d72fa560-0d4e-4a70-b8c7-2fafa0ab5555');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                      Predicted\n",
              "Id                             \n",
              " 6107424960806386948   0.007021\n",
              "-1808613790090531322   0.014067\n",
              "-2649749947427248381   0.951422\n",
              " 4684257435812939224   0.249799\n",
              "-7030158396775705152   0.030545"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.to_csv('final_3.csv')"
      ],
      "metadata": {
        "id": "vZ4xsTyOpAMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"final_3.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "C1j4TiNpo_js",
        "outputId": "ade361a2-60f6-4a90-b8ac-438d77ed62fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2d2470dd-f5b6-4193-b841-7aa03e2ff5ed\", \"final_3.csv\", 106584)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дальше не нужно..."
      ],
      "metadata": {
        "id": "cnikW5dQsR3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(500)"
      ],
      "metadata": {
        "id": "vRPQw0lWYQoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_df = pd.DataFrame(data.groupby(['Id'], as_index=False).mean())\n",
        "testing_df[testing_df.V3.isnull()].index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcxussK1ZAGJ",
        "outputId": "883e9925-d24a-4674-9df1-bd2d52f35006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([   9,   15,   18,   19,   30,   35,   39,   47,   48,   52,\n",
              "            ...\n",
              "            7655, 7664, 7668, 7673, 7674, 7676, 7682, 7693, 7700, 7712], dtype='int64', length=1775)"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(index=data[data.V3.isnull()].index)"
      ],
      "metadata": {
        "id": "mNuAqc2-ZdBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.reset_index().drop('index', axis=1)"
      ],
      "metadata": {
        "id": "Nnj9a1HnZ6hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of null values in column 1 : \" + str(data.iloc[:, :].isnull().sum()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhNlavxSPPTC",
        "outputId": "974ea5de-0e4d-4a83-e438-cc5855038063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of null values in column 1 : Id           0\n",
            "Week         0\n",
            "V1          48\n",
            "V2          48\n",
            "V3        7100\n",
            "V4        7100\n",
            "V5        7100\n",
            "V6        7100\n",
            "V7        7100\n",
            "V8        7100\n",
            "V9        7100\n",
            "V10       7100\n",
            "V11       7100\n",
            "V12       7100\n",
            "V13       7100\n",
            "V14       7100\n",
            "V15       7100\n",
            "V16       7100\n",
            "V17       7100\n",
            "V18       7100\n",
            "V19       7100\n",
            "V20       7100\n",
            "V21       7100\n",
            "V22       7100\n",
            "P1        2914\n",
            "P2        2914\n",
            "P3        2913\n",
            "P4        2913\n",
            "P5        2914\n",
            "P6        2914\n",
            "P7        2914\n",
            "P8        2913\n",
            "P9        2913\n",
            "P10       2914\n",
            "P11       2914\n",
            "P12       2914\n",
            "P13       2914\n",
            "P14       2849\n",
            "P15       2914\n",
            "P16       2914\n",
            "P17       2913\n",
            "P18       2914\n",
            "P19       2913\n",
            "P20       2914\n",
            "P21       2913\n",
            "P22       2914\n",
            "P23       2913\n",
            "P24       2914\n",
            "P25       2913\n",
            "P26       2914\n",
            "P27       2914\n",
            "target       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns = data.columns"
      ],
      "metadata": {
        "id": "2pmagF0gRTFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHziJld6RY8Q",
        "outputId": "1896af02-5e04-4c2b-b149-ae72d3c281d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Id', 'Week', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15', 'P16', 'P17', 'P18', 'P19', 'P20', 'P21', 'P22', 'P23', 'P24', 'P25', 'P26', 'P27', 'target'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data.loc[data['V3'].notnull()].V3.mean()\n",
        "# data[\"V3\"].notnull()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HaiFgZmVDsA",
        "outputId": "6528e233-55bc-401b-ff4e-e1e92bfa0937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.04619771727743493"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for column in columns[:-1]:\n",
        "    mean = data.loc[data[column].notnull()][column].mean()\n",
        "    data[column].fillna(mean, inplace=True)\n",
        "    mean = test_data.loc[test_data[column].notnull()][column].mean()\n",
        "    test_data[column].fillna(mean, inplace=True)"
      ],
      "metadata": {
        "id": "pKEnea_KRar-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data = data.fillna(0)\n",
        "# data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "ucedYcsCBQxw",
        "outputId": "65428952-aac9-4a01-e468-cf4383917e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-49175b11-3f7f-41e6-9669-d51fba15e3f7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Week</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>P1</th>\n",
              "      <th>P2</th>\n",
              "      <th>P3</th>\n",
              "      <th>P4</th>\n",
              "      <th>P5</th>\n",
              "      <th>P6</th>\n",
              "      <th>P7</th>\n",
              "      <th>P8</th>\n",
              "      <th>P9</th>\n",
              "      <th>P10</th>\n",
              "      <th>P11</th>\n",
              "      <th>P12</th>\n",
              "      <th>P13</th>\n",
              "      <th>P14</th>\n",
              "      <th>P15</th>\n",
              "      <th>P16</th>\n",
              "      <th>P17</th>\n",
              "      <th>P18</th>\n",
              "      <th>P19</th>\n",
              "      <th>P20</th>\n",
              "      <th>P21</th>\n",
              "      <th>P22</th>\n",
              "      <th>P23</th>\n",
              "      <th>P24</th>\n",
              "      <th>P25</th>\n",
              "      <th>P26</th>\n",
              "      <th>P27</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-6536978109522202983</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011364</td>\n",
              "      <td>0.006579</td>\n",
              "      <td>0.0311</td>\n",
              "      <td>0.013158</td>\n",
              "      <td>0.006579</td>\n",
              "      <td>0.228694</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333073</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019737</td>\n",
              "      <td>0.064203</td>\n",
              "      <td>0.263279</td>\n",
              "      <td>0.011364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>0.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>24137.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>5.205102</td>\n",
              "      <td>77.950000</td>\n",
              "      <td>21.400000</td>\n",
              "      <td>132.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.82</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2440.153846</td>\n",
              "      <td>301.566667</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>12.076923</td>\n",
              "      <td>11038.166667</td>\n",
              "      <td>15.400000</td>\n",
              "      <td>4.82</td>\n",
              "      <td>8.911111</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.820000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>6712.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-6536978109522202983</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011364</td>\n",
              "      <td>0.006579</td>\n",
              "      <td>0.0311</td>\n",
              "      <td>0.013158</td>\n",
              "      <td>0.006579</td>\n",
              "      <td>0.228694</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333073</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019737</td>\n",
              "      <td>0.064203</td>\n",
              "      <td>0.263279</td>\n",
              "      <td>0.011364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>43316.0</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>3.926019</td>\n",
              "      <td>105.650000</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>154.608696</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>4.82</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>1761.000000</td>\n",
              "      <td>487.050000</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>10.518868</td>\n",
              "      <td>14078.000000</td>\n",
              "      <td>17.016667</td>\n",
              "      <td>4.82</td>\n",
              "      <td>8.292754</td>\n",
              "      <td>510.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.820000</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>4873.0</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-6536978109522202983</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011364</td>\n",
              "      <td>0.006579</td>\n",
              "      <td>0.0311</td>\n",
              "      <td>0.013158</td>\n",
              "      <td>0.006579</td>\n",
              "      <td>0.228694</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333073</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019737</td>\n",
              "      <td>0.064203</td>\n",
              "      <td>0.263279</td>\n",
              "      <td>0.011364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>19961.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>3.627770</td>\n",
              "      <td>38.100000</td>\n",
              "      <td>11.766667</td>\n",
              "      <td>122.318182</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>4.82</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>1560.333333</td>\n",
              "      <td>92.733333</td>\n",
              "      <td>0.227273</td>\n",
              "      <td>7.974747</td>\n",
              "      <td>10814.454545</td>\n",
              "      <td>41.100000</td>\n",
              "      <td>4.82</td>\n",
              "      <td>9.753030</td>\n",
              "      <td>190.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.820000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>2175.0</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-6536978109522202983</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011364</td>\n",
              "      <td>0.006579</td>\n",
              "      <td>0.0311</td>\n",
              "      <td>0.013158</td>\n",
              "      <td>0.006579</td>\n",
              "      <td>0.228694</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333073</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019737</td>\n",
              "      <td>0.064203</td>\n",
              "      <td>0.263279</td>\n",
              "      <td>0.011364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>40729.0</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>3.348995</td>\n",
              "      <td>86.983333</td>\n",
              "      <td>15.366667</td>\n",
              "      <td>152.368421</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>4.78</td>\n",
              "      <td>0.131579</td>\n",
              "      <td>2028.533333</td>\n",
              "      <td>487.016667</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>17.708333</td>\n",
              "      <td>13842.052632</td>\n",
              "      <td>33.850000</td>\n",
              "      <td>4.82</td>\n",
              "      <td>10.520614</td>\n",
              "      <td>382.0</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>4.814737</td>\n",
              "      <td>0.447368</td>\n",
              "      <td>4093.0</td>\n",
              "      <td>0.394737</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1744017237843019509</td>\n",
              "      <td>0</td>\n",
              "      <td>0.051282</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.014363</td>\n",
              "      <td>0.018308</td>\n",
              "      <td>0.037632</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.180246</td>\n",
              "      <td>0.103449</td>\n",
              "      <td>0.379082</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020292</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.055489</td>\n",
              "      <td>0.071362</td>\n",
              "      <td>0.071817</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.047960</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>56986.0</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>3.916232</td>\n",
              "      <td>30.466667</td>\n",
              "      <td>5.200000</td>\n",
              "      <td>143.217391</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.152174</td>\n",
              "      <td>0.152174</td>\n",
              "      <td>4.86</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>1960.274510</td>\n",
              "      <td>105.433333</td>\n",
              "      <td>0.108696</td>\n",
              "      <td>10.819113</td>\n",
              "      <td>10859.086957</td>\n",
              "      <td>31.866667</td>\n",
              "      <td>4.94</td>\n",
              "      <td>9.438406</td>\n",
              "      <td>777.0</td>\n",
              "      <td>0.021739</td>\n",
              "      <td>4.908478</td>\n",
              "      <td>0.673913</td>\n",
              "      <td>1296.0</td>\n",
              "      <td>0.239130</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30855</th>\n",
              "      <td>2010738301694279951</td>\n",
              "      <td>3</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.006173</td>\n",
              "      <td>0.267642</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.192127</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018545</td>\n",
              "      <td>0.005747</td>\n",
              "      <td>0.289156</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008333</td>\n",
              "      <td>0.019045</td>\n",
              "      <td>0.151087</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009259</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023627</td>\n",
              "      <td>0.009259</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>27623.0</td>\n",
              "      <td>0.395062</td>\n",
              "      <td>2.587916</td>\n",
              "      <td>33.266667</td>\n",
              "      <td>7.766667</td>\n",
              "      <td>145.098765</td>\n",
              "      <td>0.037037</td>\n",
              "      <td>0.012346</td>\n",
              "      <td>0.123457</td>\n",
              "      <td>0.160494</td>\n",
              "      <td>4.96</td>\n",
              "      <td>0.234568</td>\n",
              "      <td>1196.927835</td>\n",
              "      <td>89.650000</td>\n",
              "      <td>0.135802</td>\n",
              "      <td>6.394737</td>\n",
              "      <td>10236.172840</td>\n",
              "      <td>24.100000</td>\n",
              "      <td>4.97</td>\n",
              "      <td>8.271399</td>\n",
              "      <td>406.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.966790</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>961.0</td>\n",
              "      <td>0.345679</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30856</th>\n",
              "      <td>8802977523104348852</td>\n",
              "      <td>0</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>18324.0</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>2.772570</td>\n",
              "      <td>52.750000</td>\n",
              "      <td>23.716667</td>\n",
              "      <td>132.058824</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>4.98</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>1856.666667</td>\n",
              "      <td>96.833333</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>6.177024</td>\n",
              "      <td>9226.941176</td>\n",
              "      <td>19.566667</td>\n",
              "      <td>4.98</td>\n",
              "      <td>11.681373</td>\n",
              "      <td>234.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.980000</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>3414.0</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30857</th>\n",
              "      <td>8802977523104348852</td>\n",
              "      <td>1</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>16426.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.859619</td>\n",
              "      <td>69.083333</td>\n",
              "      <td>69.083333</td>\n",
              "      <td>171.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.99</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1650.000000</td>\n",
              "      <td>69.083333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.859619</td>\n",
              "      <td>16426.000000</td>\n",
              "      <td>9.616667</td>\n",
              "      <td>4.99</td>\n",
              "      <td>9.616667</td>\n",
              "      <td>171.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.990000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16426.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30858</th>\n",
              "      <td>8802977523104348852</td>\n",
              "      <td>2</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>18247.0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>2.197785</td>\n",
              "      <td>55.216667</td>\n",
              "      <td>41.200000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>4.99</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2190.750000</td>\n",
              "      <td>71.950000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>3.478261</td>\n",
              "      <td>13744.000000</td>\n",
              "      <td>26.683333</td>\n",
              "      <td>4.99</td>\n",
              "      <td>17.962500</td>\n",
              "      <td>220.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.990000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>4588.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30859</th>\n",
              "      <td>8802977523104348852</td>\n",
              "      <td>3</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>35991.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>29.116667</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.99</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>900.000000</td>\n",
              "      <td>487.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>8080.000000</td>\n",
              "      <td>15.733333</td>\n",
              "      <td>4.99</td>\n",
              "      <td>9.350000</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30860 rows × 52 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49175b11-3f7f-41e6-9669-d51fba15e3f7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49175b11-3f7f-41e6-9669-d51fba15e3f7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49175b11-3f7f-41e6-9669-d51fba15e3f7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                        Id  Week        V1   V2        V3        V4        V5      V6        V7        V8        V9       V10       V11  V12  V13       V14       V15       V16       V17       V18  V19       V20       V21  V22     P1       P2        P3        P4          P5         P6          P7        P8        P9       P10       P11   P12       P13          P14         P15       P16        P17           P18        P19   P20        P21    P22       P23       P24       P25      P26       P27  target\n",
              "0     -6536978109522202983     0  0.000000  0.0  0.000000  0.011364  0.006579  0.0311  0.013158  0.006579  0.228694  0.000000  0.333073  0.0  0.0  0.019737  0.064203  0.263279  0.011364  0.000000  0.0  0.000000  0.010870  0.0   86.0  24137.0  0.666667  5.205102   77.950000  21.400000  132.666667  0.000000  0.000000  0.166667  0.000000  4.82  0.000000  2440.153846  301.566667  0.500000  12.076923  11038.166667  15.400000  4.82   8.911111  200.0  0.000000  4.820000  0.333333   6712.0  0.333333     0.0\n",
              "1     -6536978109522202983     1  0.000000  0.0  0.000000  0.011364  0.006579  0.0311  0.013158  0.006579  0.228694  0.000000  0.333073  0.0  0.0  0.019737  0.064203  0.263279  0.011364  0.000000  0.0  0.000000  0.010870  0.0   64.0  43316.0  0.347826  3.926019  105.650000  10.800000  154.608696  0.000000  0.000000  0.130435  0.130435  4.82  0.130435  1761.000000  487.050000  0.217391  10.518868  14078.000000  17.016667  4.82   8.292754  510.0  0.000000  4.820000  0.652174   4873.0  0.391304     0.0\n",
              "2     -6536978109522202983     2  0.000000  0.0  0.000000  0.011364  0.006579  0.0311  0.013158  0.006579  0.228694  0.000000  0.333073  0.0  0.0  0.019737  0.064203  0.263279  0.011364  0.000000  0.0  0.000000  0.010870  0.0   59.0  19961.0  0.500000  3.627770   38.100000  11.766667  122.318182  0.000000  0.000000  0.181818  0.227273  4.82  0.181818  1560.333333   92.733333  0.227273   7.974747  10814.454545  41.100000  4.82   9.753030  190.0  0.000000  4.820000  0.500000   2175.0  0.181818     0.0\n",
              "3     -6536978109522202983     3  0.000000  0.0  0.000000  0.011364  0.006579  0.0311  0.013158  0.006579  0.228694  0.000000  0.333073  0.0  0.0  0.019737  0.064203  0.263279  0.011364  0.000000  0.0  0.000000  0.010870  0.0   67.0  40729.0  0.473684  3.348995   86.983333  15.366667  152.368421  0.026316  0.026316  0.105263  0.105263  4.78  0.131579  2028.533333  487.016667  0.263158  17.708333  13842.052632  33.850000  4.82  10.520614  382.0  0.026316  4.814737  0.447368   4093.0  0.394737     0.0\n",
              "4     -1744017237843019509     0  0.051282  1.0  0.014363  0.018308  0.037632  0.0000  0.180246  0.103449  0.379082  0.000000  0.020292  0.0  0.0  0.000000  0.000000  0.055489  0.071362  0.071817  0.0  0.047960  0.000000  0.0   47.0  56986.0  0.304348  3.916232   30.466667   5.200000  143.217391  0.000000  0.000000  0.152174  0.152174  4.86  0.347826  1960.274510  105.433333  0.108696  10.819113  10859.086957  31.866667  4.94   9.438406  777.0  0.021739  4.908478  0.673913   1296.0  0.239130     0.0\n",
              "...                    ...   ...       ...  ...       ...       ...       ...     ...       ...       ...       ...       ...       ...  ...  ...       ...       ...       ...       ...       ...  ...       ...       ...  ...    ...      ...       ...       ...         ...        ...         ...       ...       ...       ...       ...   ...       ...          ...         ...       ...        ...           ...        ...   ...        ...    ...       ...       ...       ...      ...       ...     ...\n",
              "30855  2010738301694279951     3  0.111111  2.0  0.006173  0.267642  0.000000  0.0000  0.192127  0.000000  0.018545  0.005747  0.289156  0.0  0.0  0.008333  0.019045  0.151087  0.000000  0.009259  0.0  0.023627  0.009259  0.0   51.0  27623.0  0.395062  2.587916   33.266667   7.766667  145.098765  0.037037  0.012346  0.123457  0.160494  4.96  0.234568  1196.927835   89.650000  0.135802   6.394737  10236.172840  24.100000  4.97   8.271399  406.0  0.000000  4.966790  0.555556    961.0  0.345679     0.0\n",
              "30856  8802977523104348852     0  0.032258  1.0  0.000000  0.000000  0.000000  0.0000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.0   80.0  18324.0  0.941176  2.772570   52.750000  23.716667  132.058824  0.000000  0.000000  0.176471  0.176471  4.98  0.058824  1856.666667   96.833333  0.352941   6.177024   9226.941176  19.566667  4.98  11.681373  234.0  0.000000  4.980000  0.058824   3414.0  0.235294     1.0\n",
              "30857  8802977523104348852     1  0.032258  1.0  0.000000  0.000000  0.000000  0.0000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.0  171.0  16426.0  1.000000  2.859619   69.083333  69.083333  171.000000  0.000000  0.000000  0.000000  0.000000  4.99  0.000000  1650.000000   69.083333  0.000000   2.859619  16426.000000   9.616667  4.99   9.616667  171.0  0.000000  4.990000  0.000000  16426.0  1.000000     1.0\n",
              "30858  8802977523104348852     2  0.032258  1.0  0.000000  0.000000  0.000000  0.0000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.0   94.0  18247.0  0.750000  2.197785   55.216667  41.200000  160.000000  0.000000  0.000000  0.000000  0.250000  4.99  0.000000  2190.750000   71.950000  0.250000   3.478261  13744.000000  26.683333  4.99  17.962500  220.0  0.000000  4.990000  0.250000   4588.0  0.500000     1.0\n",
              "30859  8802977523104348852     3  0.032258  1.0  0.000000  0.000000  0.000000  0.0000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.0   45.0  35991.0  1.000000  1.250000   29.116667   7.000000  147.000000  0.000000  0.000000  0.000000  0.000000  4.99  0.000000   900.000000  487.066667  0.000000  10.000000   8080.000000  15.733333  4.99   9.350000  200.0  0.000000  5.000000  0.000000      0.0  0.000000     1.0\n",
              "\n",
              "[30860 rows x 52 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = data.target\n",
        "X = data.drop([\"Id\", \"Week\", \"target\"], axis=1)\n"
      ],
      "metadata": {
        "id": "LZCEcEDgDTDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)"
      ],
      "metadata": {
        "id": "HLL0c6bND9eH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azPCgGfuEAGs",
        "outputId": "e91c6ab3-5ced-4125-952c-eadcb39903fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23760, 49)"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.reshape(int(X.shape[0]/4), 4, 49)"
      ],
      "metadata": {
        "id": "nJ4mXLFYEOao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_y = []\n",
        "for i in range(0, len(y), 4):\n",
        "    real_y.append(y[i])"
      ],
      "metadata": {
        "id": "pOcvN8HQEm4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(real_y)"
      ],
      "metadata": {
        "id": "RkUbCnqbEqCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 0.2\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, shuffle=True)"
      ],
      "metadata": {
        "id": "yCC7QeUbE6cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
        "y_test = np.asarray(y_test).astype('float32').reshape((-1,1))"
      ],
      "metadata": {
        "id": "2W94eMQOGXFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.GRU(144, activation='tanh', return_sequences=True, input_shape=(4, X_train.shape[2])),\n",
        "    tf.keras.layers.GRU(86, activation='tanh', return_sequences=True),\n",
        "    tf.keras.layers.GRU(86, activation='tanh'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    \n",
        "])\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    min_delta = 0.0001,\n",
        "    patience = 15,\n",
        "    restore_best_weights = True\n",
        ")\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_split=0.3, callbacks=[early_stopping], epochs=1000, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS_P2ph0FpWF",
        "outputId": "9207c058-9f66-4976-f645-ff7765af5c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "104/104 - 7s - loss: 0.5451 - accuracy: 0.9152 - val_loss: 0.4741 - val_accuracy: 0.9004 - 7s/epoch - 64ms/step\n",
            "Epoch 2/1000\n",
            "104/104 - 1s - loss: 0.4085 - accuracy: 0.9158 - val_loss: 0.3670 - val_accuracy: 0.9004 - 858ms/epoch - 8ms/step\n",
            "Epoch 3/1000\n",
            "104/104 - 1s - loss: 0.3240 - accuracy: 0.9158 - val_loss: 0.3166 - val_accuracy: 0.9004 - 817ms/epoch - 8ms/step\n",
            "Epoch 4/1000\n",
            "104/104 - 1s - loss: 0.2848 - accuracy: 0.9158 - val_loss: 0.2951 - val_accuracy: 0.9004 - 811ms/epoch - 8ms/step\n",
            "Epoch 5/1000\n",
            "104/104 - 1s - loss: 0.2637 - accuracy: 0.9158 - val_loss: 0.2846 - val_accuracy: 0.9004 - 814ms/epoch - 8ms/step\n",
            "Epoch 6/1000\n",
            "104/104 - 1s - loss: 0.2505 - accuracy: 0.9158 - val_loss: 0.2759 - val_accuracy: 0.9004 - 821ms/epoch - 8ms/step\n",
            "Epoch 7/1000\n",
            "104/104 - 1s - loss: 0.2401 - accuracy: 0.9158 - val_loss: 0.2676 - val_accuracy: 0.9004 - 814ms/epoch - 8ms/step\n",
            "Epoch 8/1000\n",
            "104/104 - 1s - loss: 0.2325 - accuracy: 0.9158 - val_loss: 0.2589 - val_accuracy: 0.9004 - 810ms/epoch - 8ms/step\n",
            "Epoch 9/1000\n",
            "104/104 - 1s - loss: 0.2234 - accuracy: 0.9158 - val_loss: 0.2501 - val_accuracy: 0.9004 - 828ms/epoch - 8ms/step\n",
            "Epoch 10/1000\n",
            "104/104 - 1s - loss: 0.2135 - accuracy: 0.9158 - val_loss: 0.2423 - val_accuracy: 0.9004 - 824ms/epoch - 8ms/step\n",
            "Epoch 11/1000\n",
            "104/104 - 1s - loss: 0.2055 - accuracy: 0.9158 - val_loss: 0.2353 - val_accuracy: 0.9004 - 816ms/epoch - 8ms/step\n",
            "Epoch 12/1000\n",
            "104/104 - 1s - loss: 0.1979 - accuracy: 0.9158 - val_loss: 0.2298 - val_accuracy: 0.9004 - 825ms/epoch - 8ms/step\n",
            "Epoch 13/1000\n",
            "104/104 - 1s - loss: 0.1921 - accuracy: 0.9170 - val_loss: 0.2249 - val_accuracy: 0.9067 - 830ms/epoch - 8ms/step\n",
            "Epoch 14/1000\n",
            "104/104 - 1s - loss: 0.1879 - accuracy: 0.9215 - val_loss: 0.2215 - val_accuracy: 0.9109 - 811ms/epoch - 8ms/step\n",
            "Epoch 15/1000\n",
            "104/104 - 1s - loss: 0.1846 - accuracy: 0.9257 - val_loss: 0.2204 - val_accuracy: 0.9180 - 829ms/epoch - 8ms/step\n",
            "Epoch 16/1000\n",
            "104/104 - 1s - loss: 0.1828 - accuracy: 0.9269 - val_loss: 0.2170 - val_accuracy: 0.9208 - 831ms/epoch - 8ms/step\n",
            "Epoch 17/1000\n",
            "104/104 - 1s - loss: 0.1798 - accuracy: 0.9321 - val_loss: 0.2175 - val_accuracy: 0.9215 - 830ms/epoch - 8ms/step\n",
            "Epoch 18/1000\n",
            "104/104 - 1s - loss: 0.1781 - accuracy: 0.9345 - val_loss: 0.2167 - val_accuracy: 0.9208 - 837ms/epoch - 8ms/step\n",
            "Epoch 19/1000\n",
            "104/104 - 1s - loss: 0.1754 - accuracy: 0.9378 - val_loss: 0.2159 - val_accuracy: 0.9229 - 831ms/epoch - 8ms/step\n",
            "Epoch 20/1000\n",
            "104/104 - 1s - loss: 0.1738 - accuracy: 0.9375 - val_loss: 0.2134 - val_accuracy: 0.9229 - 837ms/epoch - 8ms/step\n",
            "Epoch 21/1000\n",
            "104/104 - 1s - loss: 0.1736 - accuracy: 0.9369 - val_loss: 0.2135 - val_accuracy: 0.9222 - 847ms/epoch - 8ms/step\n",
            "Epoch 22/1000\n",
            "104/104 - 1s - loss: 0.1753 - accuracy: 0.9381 - val_loss: 0.2120 - val_accuracy: 0.9222 - 825ms/epoch - 8ms/step\n",
            "Epoch 23/1000\n",
            "104/104 - 1s - loss: 0.1735 - accuracy: 0.9408 - val_loss: 0.2130 - val_accuracy: 0.9229 - 803ms/epoch - 8ms/step\n",
            "Epoch 24/1000\n",
            "104/104 - 1s - loss: 0.1720 - accuracy: 0.9396 - val_loss: 0.2121 - val_accuracy: 0.9215 - 807ms/epoch - 8ms/step\n",
            "Epoch 25/1000\n",
            "104/104 - 1s - loss: 0.1718 - accuracy: 0.9393 - val_loss: 0.2119 - val_accuracy: 0.9208 - 821ms/epoch - 8ms/step\n",
            "Epoch 26/1000\n",
            "104/104 - 1s - loss: 0.1701 - accuracy: 0.9372 - val_loss: 0.2118 - val_accuracy: 0.9201 - 827ms/epoch - 8ms/step\n",
            "Epoch 27/1000\n",
            "104/104 - 1s - loss: 0.1713 - accuracy: 0.9402 - val_loss: 0.2120 - val_accuracy: 0.9208 - 837ms/epoch - 8ms/step\n",
            "Epoch 28/1000\n",
            "104/104 - 1s - loss: 0.1704 - accuracy: 0.9408 - val_loss: 0.2097 - val_accuracy: 0.9187 - 803ms/epoch - 8ms/step\n",
            "Epoch 29/1000\n",
            "104/104 - 1s - loss: 0.1699 - accuracy: 0.9393 - val_loss: 0.2110 - val_accuracy: 0.9194 - 823ms/epoch - 8ms/step\n",
            "Epoch 30/1000\n",
            "104/104 - 1s - loss: 0.1691 - accuracy: 0.9411 - val_loss: 0.2104 - val_accuracy: 0.9194 - 854ms/epoch - 8ms/step\n",
            "Epoch 31/1000\n",
            "104/104 - 1s - loss: 0.1703 - accuracy: 0.9408 - val_loss: 0.2113 - val_accuracy: 0.9208 - 1s/epoch - 10ms/step\n",
            "Epoch 32/1000\n",
            "104/104 - 1s - loss: 0.1671 - accuracy: 0.9435 - val_loss: 0.2093 - val_accuracy: 0.9208 - 876ms/epoch - 8ms/step\n",
            "Epoch 33/1000\n",
            "104/104 - 1s - loss: 0.1687 - accuracy: 0.9390 - val_loss: 0.2105 - val_accuracy: 0.9215 - 901ms/epoch - 9ms/step\n",
            "Epoch 34/1000\n",
            "104/104 - 1s - loss: 0.1691 - accuracy: 0.9408 - val_loss: 0.2083 - val_accuracy: 0.9201 - 941ms/epoch - 9ms/step\n",
            "Epoch 35/1000\n",
            "104/104 - 1s - loss: 0.1681 - accuracy: 0.9417 - val_loss: 0.2095 - val_accuracy: 0.9201 - 849ms/epoch - 8ms/step\n",
            "Epoch 36/1000\n",
            "104/104 - 1s - loss: 0.1678 - accuracy: 0.9411 - val_loss: 0.2091 - val_accuracy: 0.9215 - 802ms/epoch - 8ms/step\n",
            "Epoch 37/1000\n",
            "104/104 - 1s - loss: 0.1668 - accuracy: 0.9444 - val_loss: 0.2093 - val_accuracy: 0.9229 - 843ms/epoch - 8ms/step\n",
            "Epoch 38/1000\n",
            "104/104 - 1s - loss: 0.1651 - accuracy: 0.9420 - val_loss: 0.2078 - val_accuracy: 0.9215 - 850ms/epoch - 8ms/step\n",
            "Epoch 39/1000\n",
            "104/104 - 1s - loss: 0.1668 - accuracy: 0.9435 - val_loss: 0.2086 - val_accuracy: 0.9215 - 854ms/epoch - 8ms/step\n",
            "Epoch 40/1000\n",
            "104/104 - 1s - loss: 0.1671 - accuracy: 0.9429 - val_loss: 0.2078 - val_accuracy: 0.9201 - 833ms/epoch - 8ms/step\n",
            "Epoch 41/1000\n",
            "104/104 - 1s - loss: 0.1642 - accuracy: 0.9420 - val_loss: 0.2082 - val_accuracy: 0.9222 - 841ms/epoch - 8ms/step\n",
            "Epoch 42/1000\n",
            "104/104 - 1s - loss: 0.1666 - accuracy: 0.9423 - val_loss: 0.2093 - val_accuracy: 0.9215 - 844ms/epoch - 8ms/step\n",
            "Epoch 43/1000\n",
            "104/104 - 1s - loss: 0.1653 - accuracy: 0.9429 - val_loss: 0.2083 - val_accuracy: 0.9208 - 848ms/epoch - 8ms/step\n",
            "Epoch 44/1000\n",
            "104/104 - 1s - loss: 0.1641 - accuracy: 0.9432 - val_loss: 0.2089 - val_accuracy: 0.9201 - 847ms/epoch - 8ms/step\n",
            "Epoch 45/1000\n",
            "104/104 - 1s - loss: 0.1650 - accuracy: 0.9429 - val_loss: 0.2084 - val_accuracy: 0.9194 - 843ms/epoch - 8ms/step\n",
            "Epoch 46/1000\n",
            "104/104 - 1s - loss: 0.1658 - accuracy: 0.9432 - val_loss: 0.2089 - val_accuracy: 0.9201 - 849ms/epoch - 8ms/step\n",
            "Epoch 47/1000\n",
            "104/104 - 1s - loss: 0.1631 - accuracy: 0.9435 - val_loss: 0.2088 - val_accuracy: 0.9208 - 834ms/epoch - 8ms/step\n",
            "Epoch 48/1000\n",
            "104/104 - 1s - loss: 0.1626 - accuracy: 0.9450 - val_loss: 0.2078 - val_accuracy: 0.9187 - 832ms/epoch - 8ms/step\n",
            "Epoch 49/1000\n",
            "104/104 - 1s - loss: 0.1649 - accuracy: 0.9435 - val_loss: 0.2080 - val_accuracy: 0.9201 - 861ms/epoch - 8ms/step\n",
            "Epoch 50/1000\n",
            "104/104 - 1s - loss: 0.1617 - accuracy: 0.9447 - val_loss: 0.2071 - val_accuracy: 0.9180 - 840ms/epoch - 8ms/step\n",
            "Epoch 51/1000\n",
            "104/104 - 1s - loss: 0.1625 - accuracy: 0.9441 - val_loss: 0.2064 - val_accuracy: 0.9158 - 821ms/epoch - 8ms/step\n",
            "Epoch 52/1000\n",
            "104/104 - 1s - loss: 0.1643 - accuracy: 0.9432 - val_loss: 0.2068 - val_accuracy: 0.9158 - 1s/epoch - 10ms/step\n",
            "Epoch 53/1000\n",
            "104/104 - 1s - loss: 0.1622 - accuracy: 0.9441 - val_loss: 0.2072 - val_accuracy: 0.9158 - 832ms/epoch - 8ms/step\n",
            "Epoch 54/1000\n",
            "104/104 - 1s - loss: 0.1636 - accuracy: 0.9423 - val_loss: 0.2074 - val_accuracy: 0.9208 - 815ms/epoch - 8ms/step\n",
            "Epoch 55/1000\n",
            "104/104 - 1s - loss: 0.1627 - accuracy: 0.9432 - val_loss: 0.2063 - val_accuracy: 0.9165 - 815ms/epoch - 8ms/step\n",
            "Epoch 56/1000\n",
            "104/104 - 1s - loss: 0.1611 - accuracy: 0.9441 - val_loss: 0.2064 - val_accuracy: 0.9180 - 831ms/epoch - 8ms/step\n",
            "Epoch 57/1000\n",
            "104/104 - 1s - loss: 0.1623 - accuracy: 0.9435 - val_loss: 0.2066 - val_accuracy: 0.9194 - 807ms/epoch - 8ms/step\n",
            "Epoch 58/1000\n",
            "104/104 - 1s - loss: 0.1625 - accuracy: 0.9423 - val_loss: 0.2066 - val_accuracy: 0.9187 - 802ms/epoch - 8ms/step\n",
            "Epoch 59/1000\n",
            "104/104 - 1s - loss: 0.1619 - accuracy: 0.9435 - val_loss: 0.2062 - val_accuracy: 0.9187 - 982ms/epoch - 9ms/step\n",
            "Epoch 60/1000\n",
            "104/104 - 1s - loss: 0.1614 - accuracy: 0.9423 - val_loss: 0.2071 - val_accuracy: 0.9208 - 812ms/epoch - 8ms/step\n",
            "Epoch 61/1000\n",
            "104/104 - 1s - loss: 0.1602 - accuracy: 0.9441 - val_loss: 0.2052 - val_accuracy: 0.9173 - 803ms/epoch - 8ms/step\n",
            "Epoch 62/1000\n",
            "104/104 - 1s - loss: 0.1621 - accuracy: 0.9444 - val_loss: 0.2064 - val_accuracy: 0.9194 - 805ms/epoch - 8ms/step\n",
            "Epoch 63/1000\n",
            "104/104 - 1s - loss: 0.1616 - accuracy: 0.9429 - val_loss: 0.2054 - val_accuracy: 0.9194 - 809ms/epoch - 8ms/step\n",
            "Epoch 64/1000\n",
            "104/104 - 1s - loss: 0.1605 - accuracy: 0.9432 - val_loss: 0.2074 - val_accuracy: 0.9215 - 810ms/epoch - 8ms/step\n",
            "Epoch 65/1000\n",
            "104/104 - 1s - loss: 0.1591 - accuracy: 0.9432 - val_loss: 0.2068 - val_accuracy: 0.9187 - 831ms/epoch - 8ms/step\n",
            "Epoch 66/1000\n",
            "104/104 - 1s - loss: 0.1584 - accuracy: 0.9438 - val_loss: 0.2067 - val_accuracy: 0.9187 - 810ms/epoch - 8ms/step\n",
            "Epoch 67/1000\n",
            "104/104 - 1s - loss: 0.1596 - accuracy: 0.9444 - val_loss: 0.2051 - val_accuracy: 0.9180 - 807ms/epoch - 8ms/step\n",
            "Epoch 68/1000\n",
            "104/104 - 1s - loss: 0.1590 - accuracy: 0.9447 - val_loss: 0.2067 - val_accuracy: 0.9194 - 814ms/epoch - 8ms/step\n",
            "Epoch 69/1000\n",
            "104/104 - 1s - loss: 0.1607 - accuracy: 0.9447 - val_loss: 0.2059 - val_accuracy: 0.9215 - 806ms/epoch - 8ms/step\n",
            "Epoch 70/1000\n",
            "104/104 - 1s - loss: 0.1590 - accuracy: 0.9456 - val_loss: 0.2060 - val_accuracy: 0.9215 - 859ms/epoch - 8ms/step\n",
            "Epoch 71/1000\n",
            "104/104 - 1s - loss: 0.1589 - accuracy: 0.9450 - val_loss: 0.2048 - val_accuracy: 0.9173 - 839ms/epoch - 8ms/step\n",
            "Epoch 72/1000\n",
            "104/104 - 1s - loss: 0.1578 - accuracy: 0.9438 - val_loss: 0.2057 - val_accuracy: 0.9173 - 838ms/epoch - 8ms/step\n",
            "Epoch 73/1000\n",
            "104/104 - 1s - loss: 0.1572 - accuracy: 0.9444 - val_loss: 0.2063 - val_accuracy: 0.9187 - 822ms/epoch - 8ms/step\n",
            "Epoch 74/1000\n",
            "104/104 - 1s - loss: 0.1623 - accuracy: 0.9435 - val_loss: 0.2045 - val_accuracy: 0.9165 - 830ms/epoch - 8ms/step\n",
            "Epoch 75/1000\n",
            "104/104 - 1s - loss: 0.1592 - accuracy: 0.9447 - val_loss: 0.2056 - val_accuracy: 0.9173 - 804ms/epoch - 8ms/step\n",
            "Epoch 76/1000\n",
            "104/104 - 1s - loss: 0.1586 - accuracy: 0.9429 - val_loss: 0.2051 - val_accuracy: 0.9173 - 825ms/epoch - 8ms/step\n",
            "Epoch 77/1000\n",
            "104/104 - 1s - loss: 0.1578 - accuracy: 0.9438 - val_loss: 0.2055 - val_accuracy: 0.9187 - 825ms/epoch - 8ms/step\n",
            "Epoch 78/1000\n",
            "104/104 - 1s - loss: 0.1594 - accuracy: 0.9441 - val_loss: 0.2058 - val_accuracy: 0.9194 - 854ms/epoch - 8ms/step\n",
            "Epoch 79/1000\n",
            "104/104 - 1s - loss: 0.1627 - accuracy: 0.9447 - val_loss: 0.2051 - val_accuracy: 0.9194 - 868ms/epoch - 8ms/step\n",
            "Epoch 80/1000\n",
            "104/104 - 1s - loss: 0.1601 - accuracy: 0.9447 - val_loss: 0.2054 - val_accuracy: 0.9194 - 875ms/epoch - 8ms/step\n",
            "Epoch 81/1000\n",
            "104/104 - 1s - loss: 0.1611 - accuracy: 0.9438 - val_loss: 0.2058 - val_accuracy: 0.9194 - 853ms/epoch - 8ms/step\n",
            "Epoch 82/1000\n",
            "104/104 - 1s - loss: 0.1577 - accuracy: 0.9450 - val_loss: 0.2057 - val_accuracy: 0.9215 - 872ms/epoch - 8ms/step\n",
            "Epoch 83/1000\n",
            "104/104 - 1s - loss: 0.1589 - accuracy: 0.9429 - val_loss: 0.2056 - val_accuracy: 0.9201 - 862ms/epoch - 8ms/step\n",
            "Epoch 84/1000\n",
            "104/104 - 1s - loss: 0.1609 - accuracy: 0.9456 - val_loss: 0.2048 - val_accuracy: 0.9187 - 865ms/epoch - 8ms/step\n",
            "Epoch 85/1000\n",
            "104/104 - 1s - loss: 0.1575 - accuracy: 0.9453 - val_loss: 0.2057 - val_accuracy: 0.9215 - 892ms/epoch - 9ms/step\n",
            "Epoch 86/1000\n",
            "104/104 - 1s - loss: 0.1581 - accuracy: 0.9453 - val_loss: 0.2051 - val_accuracy: 0.9215 - 883ms/epoch - 8ms/step\n",
            "Epoch 87/1000\n",
            "104/104 - 1s - loss: 0.1586 - accuracy: 0.9444 - val_loss: 0.2054 - val_accuracy: 0.9208 - 914ms/epoch - 9ms/step\n",
            "Epoch 88/1000\n",
            "104/104 - 1s - loss: 0.1576 - accuracy: 0.9435 - val_loss: 0.2048 - val_accuracy: 0.9215 - 878ms/epoch - 8ms/step\n",
            "Epoch 89/1000\n",
            "104/104 - 1s - loss: 0.1577 - accuracy: 0.9450 - val_loss: 0.2056 - val_accuracy: 0.9215 - 881ms/epoch - 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label = \"Training loss\")\n",
        "plt.plot(epochs, val_loss, 'r', label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "acc = history.history[\"accuracy\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "plt.plot(epochs, acc, 'y', label = \"Training acc\")\n",
        "plt.plot(epochs, val_acc, 'r', label=\"Validation acc\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "VnXXV_L5FqMF",
        "outputId": "ea4697c8-dad8-4795-d719-086f01868d50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = model.predict(X_test)\n",
        "print(\"Confusion matrix for our model is: \\n\", confusion_matrix(y_test, y_predicted.round()))\n",
        "print(\"Score of our model is: \", model.evaluate(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q26bz-M6HHRn",
        "outputId": "c6a80dda-8098-42c7-c734-8ca5d71f854b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix for our model is: \n",
            " [[1232   37]\n",
            " [ 107  167]]\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.2366 - accuracy: 0.9067\n",
            "Score of our model is:  [0.2366122156381607, 0.9066752791404724]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "S70bXL4YISVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On whole data"
      ],
      "metadata": {
        "id": "nnmgvqFhISkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.asarray(y).astype('float32').reshape((-1,1))"
      ],
      "metadata": {
        "id": "XmbXPfjyIU1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nXdrX01XNOvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.GRU(144, activation='tanh', return_sequences=True, input_shape=(4, X_train.shape[2])),\n",
        "    tf.keras.layers.GRU(86, activation='tanh', return_sequences=True),\n",
        "    tf.keras.layers.GRU(86, activation='tanh'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    \n",
        "])\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    min_delta = 0.0001,\n",
        "    patience = 25,\n",
        "    restore_best_weights = True\n",
        ")\n",
        "\n",
        "history = model.fit(X, y, validation_split=0.3, callbacks=[early_stopping], epochs=1000, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_kMR9FOILcq",
        "outputId": "15dcfb53-bb97-4306-e3b5-2ee5c268a749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "130/130 - 7s - loss: 0.6355 - accuracy: 0.7227 - val_loss: 0.5323 - val_accuracy: 0.9169 - 7s/epoch - 54ms/step\n",
            "Epoch 2/1000\n",
            "130/130 - 1s - loss: 0.4767 - accuracy: 0.9117 - val_loss: 0.3978 - val_accuracy: 0.9169 - 1s/epoch - 8ms/step\n",
            "Epoch 3/1000\n",
            "130/130 - 1s - loss: 0.3762 - accuracy: 0.9110 - val_loss: 0.3201 - val_accuracy: 0.9169 - 1s/epoch - 8ms/step\n",
            "Epoch 4/1000\n",
            "130/130 - 1s - loss: 0.3121 - accuracy: 0.9110 - val_loss: 0.2680 - val_accuracy: 0.9169 - 1s/epoch - 8ms/step\n",
            "Epoch 5/1000\n",
            "130/130 - 1s - loss: 0.2758 - accuracy: 0.9110 - val_loss: 0.2408 - val_accuracy: 0.9169 - 1s/epoch - 9ms/step\n",
            "Epoch 6/1000\n",
            "130/130 - 1s - loss: 0.2554 - accuracy: 0.9110 - val_loss: 0.2235 - val_accuracy: 0.9169 - 1s/epoch - 8ms/step\n",
            "Epoch 7/1000\n",
            "130/130 - 1s - loss: 0.2383 - accuracy: 0.9110 - val_loss: 0.2095 - val_accuracy: 0.9169 - 1s/epoch - 8ms/step\n",
            "Epoch 8/1000\n",
            "130/130 - 1s - loss: 0.2279 - accuracy: 0.9127 - val_loss: 0.1968 - val_accuracy: 0.9237 - 1s/epoch - 8ms/step\n",
            "Epoch 9/1000\n",
            "130/130 - 1s - loss: 0.2138 - accuracy: 0.9165 - val_loss: 0.1868 - val_accuracy: 0.9332 - 1s/epoch - 8ms/step\n",
            "Epoch 10/1000\n",
            "130/130 - 1s - loss: 0.2044 - accuracy: 0.9216 - val_loss: 0.1800 - val_accuracy: 0.9355 - 1s/epoch - 8ms/step\n",
            "Epoch 11/1000\n",
            "130/130 - 1s - loss: 0.2004 - accuracy: 0.9269 - val_loss: 0.1750 - val_accuracy: 0.9400 - 1s/epoch - 9ms/step\n",
            "Epoch 12/1000\n",
            "130/130 - 1s - loss: 0.1906 - accuracy: 0.9310 - val_loss: 0.1719 - val_accuracy: 0.9411 - 1s/epoch - 8ms/step\n",
            "Epoch 13/1000\n",
            "130/130 - 1s - loss: 0.1894 - accuracy: 0.9310 - val_loss: 0.1700 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 14/1000\n",
            "130/130 - 1s - loss: 0.1862 - accuracy: 0.9312 - val_loss: 0.1686 - val_accuracy: 0.9439 - 1s/epoch - 8ms/step\n",
            "Epoch 15/1000\n",
            "130/130 - 1s - loss: 0.1853 - accuracy: 0.9317 - val_loss: 0.1683 - val_accuracy: 0.9439 - 1s/epoch - 8ms/step\n",
            "Epoch 16/1000\n",
            "130/130 - 1s - loss: 0.1843 - accuracy: 0.9293 - val_loss: 0.1678 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 17/1000\n",
            "130/130 - 1s - loss: 0.1839 - accuracy: 0.9312 - val_loss: 0.1674 - val_accuracy: 0.9444 - 1s/epoch - 8ms/step\n",
            "Epoch 18/1000\n",
            "130/130 - 1s - loss: 0.1836 - accuracy: 0.9317 - val_loss: 0.1668 - val_accuracy: 0.9444 - 1s/epoch - 8ms/step\n",
            "Epoch 19/1000\n",
            "130/130 - 1s - loss: 0.1804 - accuracy: 0.9336 - val_loss: 0.1672 - val_accuracy: 0.9439 - 1s/epoch - 9ms/step\n",
            "Epoch 20/1000\n",
            "130/130 - 1s - loss: 0.1830 - accuracy: 0.9298 - val_loss: 0.1668 - val_accuracy: 0.9439 - 1s/epoch - 8ms/step\n",
            "Epoch 21/1000\n",
            "130/130 - 1s - loss: 0.1820 - accuracy: 0.9317 - val_loss: 0.1665 - val_accuracy: 0.9439 - 1s/epoch - 8ms/step\n",
            "Epoch 22/1000\n",
            "130/130 - 1s - loss: 0.1812 - accuracy: 0.9322 - val_loss: 0.1665 - val_accuracy: 0.9433 - 1s/epoch - 8ms/step\n",
            "Epoch 23/1000\n",
            "130/130 - 1s - loss: 0.1796 - accuracy: 0.9322 - val_loss: 0.1659 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 24/1000\n",
            "130/130 - 1s - loss: 0.1785 - accuracy: 0.9339 - val_loss: 0.1652 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 25/1000\n",
            "130/130 - 1s - loss: 0.1805 - accuracy: 0.9307 - val_loss: 0.1657 - val_accuracy: 0.9439 - 1s/epoch - 8ms/step\n",
            "Epoch 26/1000\n",
            "130/130 - 1s - loss: 0.1776 - accuracy: 0.9351 - val_loss: 0.1652 - val_accuracy: 0.9433 - 1s/epoch - 8ms/step\n",
            "Epoch 27/1000\n",
            "130/130 - 1s - loss: 0.1799 - accuracy: 0.9329 - val_loss: 0.1653 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 28/1000\n",
            "130/130 - 1s - loss: 0.1791 - accuracy: 0.9351 - val_loss: 0.1654 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 29/1000\n",
            "130/130 - 1s - loss: 0.1766 - accuracy: 0.9322 - val_loss: 0.1647 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 30/1000\n",
            "130/130 - 1s - loss: 0.1787 - accuracy: 0.9315 - val_loss: 0.1648 - val_accuracy: 0.9433 - 1s/epoch - 8ms/step\n",
            "Epoch 31/1000\n",
            "130/130 - 1s - loss: 0.1783 - accuracy: 0.9319 - val_loss: 0.1641 - val_accuracy: 0.9433 - 1s/epoch - 8ms/step\n",
            "Epoch 32/1000\n",
            "130/130 - 1s - loss: 0.1755 - accuracy: 0.9367 - val_loss: 0.1639 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 33/1000\n",
            "130/130 - 1s - loss: 0.1777 - accuracy: 0.9319 - val_loss: 0.1639 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 34/1000\n",
            "130/130 - 1s - loss: 0.1768 - accuracy: 0.9319 - val_loss: 0.1638 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 35/1000\n",
            "130/130 - 1s - loss: 0.1754 - accuracy: 0.9341 - val_loss: 0.1638 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 36/1000\n",
            "130/130 - 1s - loss: 0.1749 - accuracy: 0.9351 - val_loss: 0.1637 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 37/1000\n",
            "130/130 - 1s - loss: 0.1769 - accuracy: 0.9327 - val_loss: 0.1636 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 38/1000\n",
            "130/130 - 1s - loss: 0.1761 - accuracy: 0.9367 - val_loss: 0.1632 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 39/1000\n",
            "130/130 - 1s - loss: 0.1771 - accuracy: 0.9353 - val_loss: 0.1629 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 40/1000\n",
            "130/130 - 1s - loss: 0.1742 - accuracy: 0.9343 - val_loss: 0.1627 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 41/1000\n",
            "130/130 - 1s - loss: 0.1757 - accuracy: 0.9303 - val_loss: 0.1628 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 42/1000\n",
            "130/130 - 1s - loss: 0.1730 - accuracy: 0.9353 - val_loss: 0.1631 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 43/1000\n",
            "130/130 - 1s - loss: 0.1733 - accuracy: 0.9317 - val_loss: 0.1633 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 44/1000\n",
            "130/130 - 1s - loss: 0.1760 - accuracy: 0.9317 - val_loss: 0.1634 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 45/1000\n",
            "130/130 - 1s - loss: 0.1739 - accuracy: 0.9327 - val_loss: 0.1635 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 46/1000\n",
            "130/130 - 1s - loss: 0.1749 - accuracy: 0.9329 - val_loss: 0.1633 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 47/1000\n",
            "130/130 - 1s - loss: 0.1742 - accuracy: 0.9305 - val_loss: 0.1633 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 48/1000\n",
            "130/130 - 1s - loss: 0.1737 - accuracy: 0.9341 - val_loss: 0.1635 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 49/1000\n",
            "130/130 - 1s - loss: 0.1741 - accuracy: 0.9353 - val_loss: 0.1632 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 50/1000\n",
            "130/130 - 1s - loss: 0.1729 - accuracy: 0.9355 - val_loss: 0.1631 - val_accuracy: 0.9428 - 1s/epoch - 9ms/step\n",
            "Epoch 51/1000\n",
            "130/130 - 1s - loss: 0.1721 - accuracy: 0.9367 - val_loss: 0.1630 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 52/1000\n",
            "130/130 - 1s - loss: 0.1727 - accuracy: 0.9348 - val_loss: 0.1634 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 53/1000\n",
            "130/130 - 1s - loss: 0.1725 - accuracy: 0.9339 - val_loss: 0.1632 - val_accuracy: 0.9411 - 1s/epoch - 8ms/step\n",
            "Epoch 54/1000\n",
            "130/130 - 1s - loss: 0.1712 - accuracy: 0.9372 - val_loss: 0.1632 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 55/1000\n",
            "130/130 - 1s - loss: 0.1715 - accuracy: 0.9341 - val_loss: 0.1632 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 56/1000\n",
            "130/130 - 1s - loss: 0.1701 - accuracy: 0.9355 - val_loss: 0.1627 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 57/1000\n",
            "130/130 - 1s - loss: 0.1718 - accuracy: 0.9363 - val_loss: 0.1623 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 58/1000\n",
            "130/130 - 1s - loss: 0.1729 - accuracy: 0.9341 - val_loss: 0.1621 - val_accuracy: 0.9433 - 1s/epoch - 8ms/step\n",
            "Epoch 59/1000\n",
            "130/130 - 1s - loss: 0.1719 - accuracy: 0.9363 - val_loss: 0.1631 - val_accuracy: 0.9405 - 1s/epoch - 8ms/step\n",
            "Epoch 60/1000\n",
            "130/130 - 1s - loss: 0.1717 - accuracy: 0.9367 - val_loss: 0.1620 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 61/1000\n",
            "130/130 - 1s - loss: 0.1735 - accuracy: 0.9336 - val_loss: 0.1622 - val_accuracy: 0.9411 - 1s/epoch - 8ms/step\n",
            "Epoch 62/1000\n",
            "130/130 - 1s - loss: 0.1719 - accuracy: 0.9346 - val_loss: 0.1620 - val_accuracy: 0.9433 - 1s/epoch - 8ms/step\n",
            "Epoch 63/1000\n",
            "130/130 - 1s - loss: 0.1703 - accuracy: 0.9370 - val_loss: 0.1618 - val_accuracy: 0.9433 - 1s/epoch - 8ms/step\n",
            "Epoch 64/1000\n",
            "130/130 - 1s - loss: 0.1712 - accuracy: 0.9351 - val_loss: 0.1614 - val_accuracy: 0.9433 - 1s/epoch - 8ms/step\n",
            "Epoch 65/1000\n",
            "130/130 - 1s - loss: 0.1707 - accuracy: 0.9358 - val_loss: 0.1612 - val_accuracy: 0.9439 - 1s/epoch - 8ms/step\n",
            "Epoch 66/1000\n",
            "130/130 - 1s - loss: 0.1719 - accuracy: 0.9331 - val_loss: 0.1617 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 67/1000\n",
            "130/130 - 1s - loss: 0.1720 - accuracy: 0.9358 - val_loss: 0.1614 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 68/1000\n",
            "130/130 - 1s - loss: 0.1700 - accuracy: 0.9360 - val_loss: 0.1616 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 69/1000\n",
            "130/130 - 1s - loss: 0.1683 - accuracy: 0.9372 - val_loss: 0.1618 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 70/1000\n",
            "130/130 - 1s - loss: 0.1686 - accuracy: 0.9363 - val_loss: 0.1614 - val_accuracy: 0.9433 - 1s/epoch - 8ms/step\n",
            "Epoch 71/1000\n",
            "130/130 - 1s - loss: 0.1716 - accuracy: 0.9351 - val_loss: 0.1616 - val_accuracy: 0.9433 - 1s/epoch - 8ms/step\n",
            "Epoch 72/1000\n",
            "130/130 - 1s - loss: 0.1704 - accuracy: 0.9355 - val_loss: 0.1612 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 73/1000\n",
            "130/130 - 1s - loss: 0.1714 - accuracy: 0.9343 - val_loss: 0.1610 - val_accuracy: 0.9433 - 1s/epoch - 8ms/step\n",
            "Epoch 74/1000\n",
            "130/130 - 1s - loss: 0.1705 - accuracy: 0.9346 - val_loss: 0.1612 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 75/1000\n",
            "130/130 - 1s - loss: 0.1686 - accuracy: 0.9327 - val_loss: 0.1609 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 76/1000\n",
            "130/130 - 1s - loss: 0.1697 - accuracy: 0.9339 - val_loss: 0.1618 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 77/1000\n",
            "130/130 - 1s - loss: 0.1701 - accuracy: 0.9367 - val_loss: 0.1615 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 78/1000\n",
            "130/130 - 1s - loss: 0.1691 - accuracy: 0.9343 - val_loss: 0.1619 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 79/1000\n",
            "130/130 - 1s - loss: 0.1698 - accuracy: 0.9358 - val_loss: 0.1615 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 80/1000\n",
            "130/130 - 1s - loss: 0.1687 - accuracy: 0.9382 - val_loss: 0.1614 - val_accuracy: 0.9422 - 1s/epoch - 9ms/step\n",
            "Epoch 81/1000\n",
            "130/130 - 1s - loss: 0.1705 - accuracy: 0.9339 - val_loss: 0.1613 - val_accuracy: 0.9411 - 1s/epoch - 8ms/step\n",
            "Epoch 82/1000\n",
            "130/130 - 1s - loss: 0.1672 - accuracy: 0.9346 - val_loss: 0.1618 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 83/1000\n",
            "130/130 - 1s - loss: 0.1681 - accuracy: 0.9353 - val_loss: 0.1619 - val_accuracy: 0.9405 - 1s/epoch - 8ms/step\n",
            "Epoch 84/1000\n",
            "130/130 - 1s - loss: 0.1678 - accuracy: 0.9367 - val_loss: 0.1613 - val_accuracy: 0.9433 - 1s/epoch - 8ms/step\n",
            "Epoch 85/1000\n",
            "130/130 - 1s - loss: 0.1677 - accuracy: 0.9334 - val_loss: 0.1612 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 86/1000\n",
            "130/130 - 1s - loss: 0.1673 - accuracy: 0.9351 - val_loss: 0.1614 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 87/1000\n",
            "130/130 - 1s - loss: 0.1682 - accuracy: 0.9355 - val_loss: 0.1615 - val_accuracy: 0.9416 - 1s/epoch - 9ms/step\n",
            "Epoch 88/1000\n",
            "130/130 - 1s - loss: 0.1674 - accuracy: 0.9360 - val_loss: 0.1611 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 89/1000\n",
            "130/130 - 1s - loss: 0.1682 - accuracy: 0.9384 - val_loss: 0.1610 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 90/1000\n",
            "130/130 - 1s - loss: 0.1700 - accuracy: 0.9358 - val_loss: 0.1616 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 91/1000\n",
            "130/130 - 1s - loss: 0.1676 - accuracy: 0.9365 - val_loss: 0.1613 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 92/1000\n",
            "130/130 - 1s - loss: 0.1675 - accuracy: 0.9372 - val_loss: 0.1609 - val_accuracy: 0.9422 - 1s/epoch - 9ms/step\n",
            "Epoch 93/1000\n",
            "130/130 - 1s - loss: 0.1668 - accuracy: 0.9367 - val_loss: 0.1611 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 94/1000\n",
            "130/130 - 1s - loss: 0.1656 - accuracy: 0.9380 - val_loss: 0.1612 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 95/1000\n",
            "130/130 - 1s - loss: 0.1656 - accuracy: 0.9367 - val_loss: 0.1607 - val_accuracy: 0.9405 - 1s/epoch - 8ms/step\n",
            "Epoch 96/1000\n",
            "130/130 - 1s - loss: 0.1673 - accuracy: 0.9365 - val_loss: 0.1607 - val_accuracy: 0.9405 - 1s/epoch - 8ms/step\n",
            "Epoch 97/1000\n",
            "130/130 - 1s - loss: 0.1648 - accuracy: 0.9382 - val_loss: 0.1616 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 98/1000\n",
            "130/130 - 1s - loss: 0.1660 - accuracy: 0.9343 - val_loss: 0.1613 - val_accuracy: 0.9411 - 1s/epoch - 8ms/step\n",
            "Epoch 99/1000\n",
            "130/130 - 1s - loss: 0.1672 - accuracy: 0.9372 - val_loss: 0.1611 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 100/1000\n",
            "130/130 - 1s - loss: 0.1658 - accuracy: 0.9365 - val_loss: 0.1617 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 101/1000\n",
            "130/130 - 1s - loss: 0.1671 - accuracy: 0.9377 - val_loss: 0.1615 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 102/1000\n",
            "130/130 - 1s - loss: 0.1674 - accuracy: 0.9351 - val_loss: 0.1612 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 103/1000\n",
            "130/130 - 1s - loss: 0.1655 - accuracy: 0.9365 - val_loss: 0.1615 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 104/1000\n",
            "130/130 - 1s - loss: 0.1651 - accuracy: 0.9375 - val_loss: 0.1610 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 105/1000\n",
            "130/130 - 1s - loss: 0.1667 - accuracy: 0.9380 - val_loss: 0.1605 - val_accuracy: 0.9405 - 991ms/epoch - 8ms/step\n",
            "Epoch 106/1000\n",
            "130/130 - 1s - loss: 0.1658 - accuracy: 0.9382 - val_loss: 0.1611 - val_accuracy: 0.9405 - 1s/epoch - 8ms/step\n",
            "Epoch 107/1000\n",
            "130/130 - 1s - loss: 0.1655 - accuracy: 0.9377 - val_loss: 0.1608 - val_accuracy: 0.9405 - 980ms/epoch - 8ms/step\n",
            "Epoch 108/1000\n",
            "130/130 - 1s - loss: 0.1657 - accuracy: 0.9392 - val_loss: 0.1612 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 109/1000\n",
            "130/130 - 1s - loss: 0.1655 - accuracy: 0.9367 - val_loss: 0.1610 - val_accuracy: 0.9405 - 1s/epoch - 8ms/step\n",
            "Epoch 110/1000\n",
            "130/130 - 1s - loss: 0.1645 - accuracy: 0.9382 - val_loss: 0.1614 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 111/1000\n",
            "130/130 - 1s - loss: 0.1648 - accuracy: 0.9396 - val_loss: 0.1611 - val_accuracy: 0.9411 - 1s/epoch - 8ms/step\n",
            "Epoch 112/1000\n",
            "130/130 - 1s - loss: 0.1667 - accuracy: 0.9360 - val_loss: 0.1621 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 113/1000\n",
            "130/130 - 1s - loss: 0.1649 - accuracy: 0.9406 - val_loss: 0.1611 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 114/1000\n",
            "130/130 - 1s - loss: 0.1652 - accuracy: 0.9365 - val_loss: 0.1619 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 115/1000\n",
            "130/130 - 1s - loss: 0.1637 - accuracy: 0.9399 - val_loss: 0.1620 - val_accuracy: 0.9411 - 990ms/epoch - 8ms/step\n",
            "Epoch 116/1000\n",
            "130/130 - 1s - loss: 0.1644 - accuracy: 0.9392 - val_loss: 0.1617 - val_accuracy: 0.9416 - 1s/epoch - 8ms/step\n",
            "Epoch 117/1000\n",
            "130/130 - 1s - loss: 0.1647 - accuracy: 0.9382 - val_loss: 0.1621 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 118/1000\n",
            "130/130 - 1s - loss: 0.1651 - accuracy: 0.9389 - val_loss: 0.1615 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 119/1000\n",
            "130/130 - 1s - loss: 0.1638 - accuracy: 0.9377 - val_loss: 0.1620 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 120/1000\n",
            "130/130 - 1s - loss: 0.1644 - accuracy: 0.9355 - val_loss: 0.1614 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 121/1000\n",
            "130/130 - 1s - loss: 0.1644 - accuracy: 0.9365 - val_loss: 0.1622 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 122/1000\n",
            "130/130 - 1s - loss: 0.1627 - accuracy: 0.9377 - val_loss: 0.1619 - val_accuracy: 0.9411 - 989ms/epoch - 8ms/step\n",
            "Epoch 123/1000\n",
            "130/130 - 1s - loss: 0.1635 - accuracy: 0.9360 - val_loss: 0.1614 - val_accuracy: 0.9428 - 976ms/epoch - 8ms/step\n",
            "Epoch 124/1000\n",
            "130/130 - 1s - loss: 0.1625 - accuracy: 0.9392 - val_loss: 0.1613 - val_accuracy: 0.9400 - 1s/epoch - 8ms/step\n",
            "Epoch 125/1000\n",
            "130/130 - 1s - loss: 0.1615 - accuracy: 0.9377 - val_loss: 0.1624 - val_accuracy: 0.9422 - 994ms/epoch - 8ms/step\n",
            "Epoch 126/1000\n",
            "130/130 - 1s - loss: 0.1648 - accuracy: 0.9387 - val_loss: 0.1620 - val_accuracy: 0.9422 - 978ms/epoch - 8ms/step\n",
            "Epoch 127/1000\n",
            "130/130 - 1s - loss: 0.1643 - accuracy: 0.9375 - val_loss: 0.1616 - val_accuracy: 0.9405 - 988ms/epoch - 8ms/step\n",
            "Epoch 128/1000\n",
            "130/130 - 1s - loss: 0.1621 - accuracy: 0.9377 - val_loss: 0.1618 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n",
            "Epoch 129/1000\n",
            "130/130 - 1s - loss: 0.1637 - accuracy: 0.9372 - val_loss: 0.1626 - val_accuracy: 0.9422 - 1s/epoch - 8ms/step\n",
            "Epoch 130/1000\n",
            "130/130 - 1s - loss: 0.1622 - accuracy: 0.9394 - val_loss: 0.1621 - val_accuracy: 0.9428 - 1s/epoch - 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_final = test_data.drop([\"Week\"], axis=1)"
      ],
      "metadata": {
        "id": "t1WSjv13Ikug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = []\n",
        "for i in range(0, len(X_final), 4):\n",
        "    ids.append(str(X_final.Id[i]))"
      ],
      "metadata": {
        "id": "ZyHdsYQ6JRlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_final = X_final.drop([\"Id\"], axis=1)"
      ],
      "metadata": {
        "id": "vE4LlJLoMAVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_final = np.array(X_final)\n",
        "X_final = X_final.reshape(int(X_final.shape[0]/4), 4, 49)"
      ],
      "metadata": {
        "id": "RNdlDi_0I8Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(X_final).round()\n",
        "prediction = prediction.reshape(int(prediction.shape[0]))"
      ],
      "metadata": {
        "id": "5vK7FAaLMEAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = pd.DataFrame(data={\"Id\": ids, \"Predicted\": prediction})"
      ],
      "metadata": {
        "id": "Uhz-hTYjMIhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final.Predicted.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ya9cLMlMKO7",
        "outputId": "88df6066-9c46-4da2-cfd9-4ef5716a30ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    3108\n",
              "1.0     199\n",
              "Name: Predicted, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final.Predicted.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL6Pu_WONfUo",
        "outputId": "c04d5e61-daa2-484e-d566-cc100a710718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final.to_csv(\"/content/drive/MyDrive/hacks/final.csv\", index=False)"
      ],
      "metadata": {
        "id": "y1obn4G5Njgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/drive/MyDrive/hacks/final.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "9wXHKOyaOqGE",
        "outputId": "b29e3a20-f2c6-4e3d-9ea8-73d2f18bf53c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_84fc0f43-f883-402e-8ff9-02aa4e7ee7be\", \"final.csv\", 80582)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final = final.fillna(0)"
      ],
      "metadata": {
        "id": "0R5fnZ2tMfkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final.Predicted.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngySAOc_NA9g",
        "outputId": "5111bdc9-02c7-4950-cc29-bdfc5b948871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    3195\n",
              "1.0     112\n",
              "Name: Predicted, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NlYxdBzKOHqm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}